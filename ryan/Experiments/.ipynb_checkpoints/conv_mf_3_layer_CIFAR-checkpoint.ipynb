{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../../savanna/')\n",
    "\n",
    "from savanna.utils.dataset import *\n",
    "from savanna.inference.conv_mf import ConvMF\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(250, 200)\n",
    "        self.fc2 = nn.Linear(200, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, b):\n",
    "        d = b.view(-1, 250)\n",
    "        d = F.relu(self.fc1(d))\n",
    "        d = F.relu(self.fc2(d))\n",
    "        d = self.fc3(d)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Data Loading\n",
    "trainset, testset = get_dataset(\"./CIFAR\", \"CIFAR10\", is_numpy=False)\n",
    "train_images = trainset.data\n",
    "train_labels = trainset.targets\n",
    "\n",
    "test_images = testset.data\n",
    "test_labels = testset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR10' object has no attribute 'train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b1ba85b76b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Data Loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./CIFAR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CIFAR10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/savanna/savanna/utils/dataset.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(data_path, dataset_name, is_numpy)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CIFAR10\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CIFAR10' object has no attribute 'train_data'"
     ]
    }
   ],
   "source": [
    "#Data Loading\n",
    "(train_images, train_labels), (test_images, test_labels) = get_dataset(\"./CIFAR\", \"CIFAR10\", is_numpy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MorF = ConvMF(tree_type = \"S-RerF\", type = 'split_forest', num_trees = 25, num_split_trees = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = MorF.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1 , 0.  , 0.  , 0.78, 0.02, 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.  , 0.  , 0.84, 0.02, 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.06, 0.  , 0.02, 0.84, 0.  , 0.02, 0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.82, 0.  , 0.  , 0.08, 0.  , 0.  , 0.  ],\n",
       "       [0.12, 0.  , 0.  , 0.8 , 0.  , 0.  , 0.08, 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.  , 0.02, 0.86, 0.02, 0.  , 0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.  , 0.02, 0.86, 0.  , 0.  , 0.06, 0.  , 0.02, 0.  ],\n",
       "       [0.04, 0.02, 0.  , 0.88, 0.  , 0.  , 0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.16, 0.  , 0.  , 0.78, 0.  , 0.  , 0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.08, 0.02, 0.  , 0.82, 0.  , 0.  , 0.08, 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.8 , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.04, 0.76, 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.02, 0.78, 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.04, 0.02, 0.84, 0.  , 0.  , 0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.08, 0.  , 0.  , 0.86, 0.  , 0.  , 0.06, 0.  , 0.  , 0.  ],\n",
       "       [0.12, 0.  , 0.  , 0.78, 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.78, 0.  , 0.  , 0.12, 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.8 , 0.02, 0.  , 0.08, 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.76, 0.  , 0.  , 0.14, 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.8 , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.04, 0.  , 0.  , 0.84, 0.  , 0.  , 0.12, 0.  , 0.  , 0.  ],\n",
       "       [0.08, 0.  , 0.  , 0.82, 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.16, 0.  , 0.02, 0.7 , 0.02, 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.1 , 0.  , 0.  , 0.78, 0.02, 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.12, 0.  , 0.  , 0.8 , 0.02, 0.  , 0.06, 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.485\n",
      "[1,  1000] loss: 0.089\n",
      "[1,  1500] loss: 0.009\n",
      "[1,  2000] loss: 0.004\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "temp = MorF.fit(train_images, train_labels)\n",
    "temp = torch.from_numpy(temp)\n",
    "temp = temp.double()\n",
    "net = CustomNet()\n",
    "n = net.double()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "running_loss = 0.0\n",
    "for i in range(2000):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    #inputs, labels = data\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(temp)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #add scoring\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 500 == 499:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "                #add score\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './fashionmnist_net2.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = MorF.predict(test_images)\n",
    "temp = torch.from_numpy(temp)\n",
    "temp = temp.double()\n",
    "count = 0\n",
    "output = net(temp)\n",
    "_, predicted= torch.max(output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MorF + NN Accuracy\n",
      "0.8773\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "predicted = predicted.numpy()\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == test_labels[i]:\n",
    "        count += 1\n",
    "score = count/nsamples\n",
    "print(\"MorF + NN Accuracy\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MorF Accuracy\n",
      "0.8774\n"
     ]
    }
   ],
   "source": [
    "results = MorF.final_predict(test_images)\n",
    "count = 0\n",
    "for i in range(len(results)):\n",
    "    if results[i] == testset[1][i]:\n",
    "        count += 1\n",
    "score = count/nsamples\n",
    "print(\"MorF Accuracy\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
