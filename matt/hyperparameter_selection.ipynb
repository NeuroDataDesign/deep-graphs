{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/matt/anaconda3/lib/python3.7/site-packages/napari/__init__.py:38: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.12.1. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "import brainlit\n",
    "from brainlit.utils.ngl_pipeline import NeuroglancerSession\n",
    "from brainlit.viz.swc import *\n",
    "from brainlit.viz.visualize import *\n",
    "from brainlit.algorithms.generate_fragments import tube_seg, adaptive_thresh\n",
    "import napari\n",
    "from skimage import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def napari_viewer(img, labels=None, shapes=None, label_name=\"Segmentation\"):\n",
    "    #with napari.gui_qt():\n",
    "    viewer = napari.view_image(np.squeeze(np.array(img)))\n",
    "    if labels is not None:\n",
    "        viewer.add_labels(labels, name=label_name)\n",
    "    if shapes is not None:\n",
    "        viewer.add_shapes(data=shapes, shape_type='path', edge_color='blue', name='Skeleton')\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(point, scales, swc_offset, brain_offset, vol_offset):\n",
    "    im_offset = np.add(brain_offset, vol_offset)\n",
    "    offset_diff = np.subtract(swc_offset, im_offset)\n",
    "    return (point + offset_diff)/scales*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seed(subneuron_df, scales, swc_offset, brain_offset, vol_offset):\n",
    "    seed = []\n",
    "    for index, row in subneuron_df.iterrows():\n",
    "        point = np.array((row['x'], row['y'], row['z']))\n",
    "        point = transform(point, scales, swc_offset, brain_offset, vol_offset)\n",
    "        _, s = adaptive_thresh.get_seed(point)\n",
    "        seed.append(s)\n",
    "    print(seed)\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/matt/Documents/brainlit/benchmarking_datasets/\"\n",
    "swc_dir = data_dir + \"Manual-GT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = data_dir + \"validation_1-gfp.tif\"\n",
    "swc_path = swc_dir + \"10-01_validation_1-5/10-01_validation_1/tree_1.swc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = np.array([298.66187, 301.37174, 1050.67223])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_offset = [73448.511531, 14630.940220, 33145.238458]\n",
    "brain_offset = [69445.19581378, 12917.40798423, 30199.63896704]\n",
    "vol_offset = [3944.427317, 1689.489974, 2904.058044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(im_path).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "napari requires a Qt event loop to run. To create one, try one of the following: \n  - use the `napari.gui_qt()` context manager. See https://github.com/napari/napari/tree/master/examples for usage examples.\n  - In IPython or a local Jupyter instance, use the `%gui qt` magic command.\n  - Launch IPython with the option `--gui=qt`.\n  - (recommended) in your IPython configuration file, add or uncomment the line `c.TerminalIPythonApp.gui = 'qt'`. Then, restart IPython.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ba1fc6650226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gui'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnapari_viewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ab90668c0e6a>\u001b[0m in \u001b[0;36mnapari_viewer\u001b[0;34m(img, labels, shapes, label_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnapari_viewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Segmentation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#with napari.gui_qt():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnapari\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/napari/view_layers.py\u001b[0m in \u001b[0;36mview_image\u001b[0;34m(data, channel_axis, rgb, colormap, contrast_limits, gamma, interpolation, rendering, iso_threshold, attenuation, name, metadata, scale, translate, opacity, blending, visible, multiscale, title, ndisplay, order, axis_labels, show)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0maxis_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     viewer.add_image(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/napari/viewer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, ndisplay, order, axis_labels, show)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;34m\" Then, restart IPython.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             )\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlogopath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resources'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logo.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: napari requires a Qt event loop to run. To create one, try one of the following: \n  - use the `napari.gui_qt()` context manager. See https://github.com/napari/napari/tree/master/examples for usage examples.\n  - In IPython or a local Jupyter instance, use the `%gui qt` magic command.\n  - Launch IPython with the option `--gui=qt`.\n  - (recommended) in your IPython configuration file, add or uncomment the line `c.TerminalIPythonApp.gui = 'qt'`. Then, restart IPython."
     ]
    }
   ],
   "source": [
    "%gui qt\n",
    "napari_viewer(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subneuron_df = pd.read_csv(swc_path, skiprows = 3, header = None, sep = \" \")\n",
    "subneuron_df.columns = [\"sample\",  \"structure\",      \"x\",      \"y\",      \"z\",\n",
    "                         \"r\",  \"parent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 127\n",
      "Number of edges: 126\n",
      "\n",
      "\n",
      "Sample 1 coordinates (x,y,z)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 13, 'y': -30, 'z': -13}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = df_to_graph(subneuron_df)\n",
    "print('Number of nodes:', len(G.nodes))\n",
    "print('Number of edges:', len(G.edges))\n",
    "print('\\n')\n",
    "print('Sample 1 coordinates (x,y,z)')\n",
    "G.nodes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = graph_to_paths(G)\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_paths = []\n",
    "for i in range(len(paths)):\n",
    "    transformed_paths.append(transform(paths[i], scales, swc_offset, brain_offset, vol_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(26, -21, 243), (27, -20, 243), (28, -19, 242), (28, -18, 242), (28, -12, 236), (28, -11, 236), (28, -6, 231), (29, -5, 230), (29, -4, 229), (29, 0, 229), (29, 0, 228), (29, 1, 227), (29, 2, 226), (29, 4, 226), (29, 6, 224), (29, 7, 224), (29, 9, 222), (29, 11, 222), (29, 19, 222), (30, 20, 222), (30, 21, 222), (30, 22, 221), (30, 23, 221), (30, 24, 220), (30, 25, 220), (30, 26, 219), (30, 28, 219), (31, 29, 218), (31, 31, 216), (31, 32, 216), (32, 33, 215), (32, 34, 215), (32, 37, 212), (33, 38, 212), (33, 39, 213), (33, 40, 213), (33, 41, 212), (33, 40, 213), (35, 42, 211), (35, 45, 211), (35, 47, 209), (35, 48, 208), (35, 48, 206), (35, 49, 205), (36, 50, 204), (36, 51, 204), (36, 53, 202), (37, 53, 202), (38, 54, 202), (38, 55, 203), (38, 57, 203), (39, 58, 203), (39, 60, 203), (39, 62, 201), (39, 63, 201), (39, 64, 200), (39, 65, 200), (39, 70, 195), (39, 72, 195), (39, 73, 194), (39, 83, 194), (39, 84, 194), (40, 85, 193), (40, 86, 193), (40, 87, 192), (40, 89, 192), (40, 90, 191), (40, 91, 191), (41, 92, 190), (41, 93, 189), (42, 94, 188), (42, 95, 187), (42, 97, 187), (42, 98, 186), (42, 100, 186), (42, 101, 185), (42, 102, 185), (42, 103, 184), (42, 105, 184), (43, 106, 183), (43, 107, 183), (43, 108, 182), (44, 109, 181), (44, 110, 180), (44, 112, 180), (45, 113, 179), (45, 115, 179), (46, 116, 178), (46, 117, 178), (46, 118, 177), (46, 119, 177), (46, 120, 176), (46, 122, 176), (46, 123, 175), (46, 125, 175), (46, 126, 174), (46, 127, 174), (46, 128, 173), (46, 133, 173), (46, 134, 172), (46, 138, 172), (46, 139, 171), (46, 141, 171), (46, 142, 170), (46, 143, 170), (46, 144, 169), (47, 144, 169), (47, 145, 169), (46, 146, 168), (47, 147, 167), (47, 149, 167), (47, 150, 166), (48, 151, 166), (48, 154, 166), (48, 157, 169), (48, 158, 168), (48, 160, 168), (49, 161, 167), (49, 163, 165), (49, 165, 165), (49, 166, 164), (49, 167, 164), (50, 168, 163), (50, 170, 163), (50, 171, 163), (50, 174, 160), (50, 174, 159)]\n"
     ]
    }
   ],
   "source": [
    "seed = create_seed(subneuron_df, scales, swc_offset, brain_offset, vol_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tube_seg.tubes_seg(im, transformed_paths[0], 2, spheres=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x7f1d6365dd90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt\n",
    "napari_viewer(im, labels = labels, shapes=transformed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "viewer = napari_viewer(im, labels=labels, shapes=transformed_paths, label_name=\"Tube Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Can't have negative coordinates in confidence_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.confidence_connected_threshold(im, [seed[10], seed[20]], num_iter=1, multiplier=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(26, -21, 243), (27, -20, 243), (28, -19, 242), (28, -18, 242), (28, -12, 236), (28, -11, 236), (28, -6, 231), (29, -5, 230), (29, -4, 229), (29, 0, 229), (29, 0, 228), (29, 1, 227), (29, 2, 226), (29, 4, 226), (29, 6, 224), (29, 7, 224), (29, 9, 222), (29, 11, 222), (29, 19, 222), (30, 20, 222), (30, 21, 222), (30, 22, 221), (30, 23, 221), (30, 24, 220), (30, 25, 220), (30, 26, 219), (30, 28, 219), (31, 29, 218), (31, 31, 216), (31, 32, 216), (32, 33, 215), (32, 34, 215), (32, 37, 212), (33, 38, 212), (33, 39, 213), (33, 40, 213), (33, 41, 212), (33, 40, 213), (35, 42, 211), (35, 45, 211), (35, 47, 209), (35, 48, 208), (35, 48, 206), (35, 49, 205), (36, 50, 204), (36, 51, 204), (36, 53, 202), (37, 53, 202), (38, 54, 202), (38, 55, 203), (38, 57, 203), (39, 58, 203), (39, 60, 203), (39, 62, 201), (39, 63, 201), (39, 64, 200), (39, 65, 200), (39, 70, 195), (39, 72, 195), (39, 73, 194), (39, 83, 194), (39, 84, 194), (40, 85, 193), (40, 86, 193), (40, 87, 192), (40, 89, 192), (40, 90, 191), (40, 91, 191), (41, 92, 190), (41, 93, 189), (42, 94, 188), (42, 95, 187), (42, 97, 187), (42, 98, 186), (42, 100, 186), (42, 101, 185), (42, 102, 185), (42, 103, 184), (42, 105, 184), (43, 106, 183), (43, 107, 183), (43, 108, 182), (44, 109, 181), (44, 110, 180), (44, 112, 180), (45, 113, 179), (45, 115, 179), (46, 116, 178), (46, 117, 178), (46, 118, 177), (46, 119, 177), (46, 120, 176), (46, 122, 176), (46, 123, 175), (46, 125, 175), (46, 126, 174), (46, 127, 174), (46, 128, 173), (46, 133, 173), (46, 134, 172), (46, 138, 172), (46, 139, 171), (46, 141, 171), (46, 142, 170), (46, 143, 170), (46, 144, 169), (47, 144, 169), (47, 145, 169), (46, 146, 168), (47, 147, 167), (47, 149, 167), (47, 150, 166), (48, 151, 166), (48, 154, 166), (48, 157, 169), (48, 158, 168), (48, 160, 168), (49, 161, 167), (49, 163, 165), (49, 165, 165), (49, 166, 164), (49, 167, 164), (50, 168, 163), (50, 170, 163), (50, 171, 163), (50, 174, 160), (50, 174, 159)]\n"
     ]
    }
   ],
   "source": [
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "viewer = napari_viewer(im, labels=labels, shapes=transformed_paths, label_name=\"Region Growing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
