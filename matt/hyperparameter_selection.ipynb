{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/matt/Documents/brainlit/benchmarking_datasets/\"\n",
    "swc_dir = data_dir + \"Manual-GT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Match image and SWC files\n",
    "im_name = \"validation_1-gfp.tif\" # choose the file name\n",
    "swc_name = \"10-01_validation_1-5/10-01_validation_1/tree_1.swc\" # choose the tree within the file (there may be many SWCs for one image)\n",
    "vol_offset = [3944.427317, 1689.489974, 2904.058044] # Use the volume offset [x1, y1, z1] from https://docs.google.com/spreadsheets/d/1DtYB-O0CjoPQcxQq_N6kVgeHV91Hmz9ac1HlhfX95og/edit#gid=1836493523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "tube_radius = 2 # value > 0. The radius of the tube for the tube segmentation. Higher radius results in a larger colored region.\n",
    "region_growing_multiplier = 0.1 # value > 0, usually not more than 1. The multiplier for region growing. Higher multipler results in a larger colored region.\n",
    "skip = 20 # use every spip'th point to generate the segmentation; e.g. every 2nd point or every 20th point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/matt/anaconda3/lib/python3.7/site-packages/napari/__init__.py:38: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.12.1. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "import brainlit\n",
    "from brainlit.utils.ngl_pipeline import NeuroglancerSession\n",
    "from brainlit.viz.swc import *\n",
    "from brainlit.viz.visualize import *\n",
    "from brainlit.algorithms.generate_fragments import tube_seg, adaptive_thresh\n",
    "import napari\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import linecache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def napari_viewer(img, labels=None, shapes=None, label_name=\"Segmentation\"):\n",
    "    #with napari.gui_qt():\n",
    "    viewer = napari.view_image(np.squeeze(np.array(img)))\n",
    "    if labels is not None:\n",
    "        viewer.add_labels(labels, name=label_name)\n",
    "    if shapes is not None:\n",
    "        viewer.add_shapes(data=shapes, shape_type='path', edge_color='blue', name='Skeleton')\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(point, scales, swc_offset, brain_offset, vol_offset):\n",
    "    im_offset = np.add(brain_offset, vol_offset)\n",
    "    offset_diff = np.subtract(swc_offset, im_offset)\n",
    "    return (point + offset_diff)/scales*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seed(subneuron_df, scales, swc_offset, brain_offset, vol_offset):\n",
    "    seed = []\n",
    "    for index, row in subneuron_df.iterrows():\n",
    "        point = np.array((row['x'], row['y'], row['z']))\n",
    "        point = transform(point, scales, swc_offset, brain_offset, vol_offset)\n",
    "        _, s = adaptive_thresh.get_seed(point)\n",
    "        seed.append(s)\n",
    "    #print(seed)\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = data_dir + im_name\n",
    "swc_path = swc_dir + swc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = np.array([298.66187, 301.37174, 1050.67223])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SWC offset is at the top of the SWC file\n",
    "swc_offset = [float(i) for i in linecache.getline(swc_path, 2).split()[2:5]]\n",
    "\n",
    "if im_name[0] == \"v\":\n",
    "    brain_offset = [69445.19581378, 12917.40798423, 30199.63896704] # validation offset\n",
    "elif im_name[0] == \"t\":\n",
    "    brain_offset = [70093.27584462, 15071.5958194, 29306.73645404] # test offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(im_path).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x7f11316982d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt\n",
    "napari_viewer(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subneuron_df = pd.read_csv(swc_path, skiprows = 3, header = None, sep = \" \")\n",
    "subneuron_df.columns = [\"sample\",  \"structure\",      \"x\",      \"y\",      \"z\",\n",
    "                         \"r\",  \"parent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 127\n",
      "Number of edges: 126\n",
      "\n",
      "\n",
      "Sample 1 coordinates (x,y,z)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 13, 'y': -30, 'z': -13}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = df_to_graph(subneuron_df)\n",
    "print('Number of nodes:', len(G.nodes))\n",
    "print('Number of edges:', len(G.edges))\n",
    "print('\\n')\n",
    "print('Sample 1 coordinates (x,y,z)')\n",
    "G.nodes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = graph_to_paths(G)\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_paths = []\n",
    "for i in range(len(paths)):\n",
    "    transformed_paths.append(transform(paths[i], scales, swc_offset, brain_offset, vol_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = create_seed(subneuron_df, scales, swc_offset, brain_offset, vol_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = [s for s in seed if s[0] >= 0 and s[1] >= 0 and s[2] >= 0] ## NOTE: Can't have negative coordinates in confidence connected threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x7f111de7b810>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt\n",
    "napari_viewer(im, labels = labels, shapes=transformed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tube_seg.tubes_seg(im, transformed_paths[0][::skip], 2, spheres=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "viewer = napari_viewer(im, labels=labels, shapes=transformed_paths, label_name=\"Tube Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.confidence_connected_threshold(im, seed[::skip], num_iter=1, multiplier=region_growing_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "viewer = napari_viewer(im, labels=labels, shapes=transformed_paths, label_name=\"Region Growing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
