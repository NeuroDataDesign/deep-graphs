{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/python_jsonschema_objects/__init__.py:53: UserWarning: Schema version http://json-schema.org/draft-04/schema not recognized. Some keywords and features may not be supported.\n",
      "  self.schema[\"$schema\"]\n"
     ]
    }
   ],
   "source": [
    "import brainlit\n",
    "from brainlit.utils.ngl_pipeline import NeuroglancerSession\n",
    "from brainlit.viz.swc import *\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading entire neuron from AWS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`napari.components.viewer_model.ViewerModel.add_swc` does this via the following functions in the `napari.layers.swc.swc` module\n",
    "1. `swc.read_s3` to read the s3 file into a pd.DataFrame\n",
    "2. `swc.read_swc` to read the swc file into a pd.DataFrame\n",
    "3. `swc.generate_df_subset` creates a smaller subset of the original dataframe with coordinates in img space\n",
    "4. `swc.swc_to_voxel` to convert the coordinates from spatial to voxel coordinates\n",
    "5. `swc.df_to_graph` to convert the DataFrame into a netwrokx.DiGraph\n",
    "6. `swc.graph_to_paths` to convert from a graph into a list of paths\n",
    "7. `ViewerModel.add_shapes` to add the paths as a shape layer into the napari viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `read_s3`\n",
    "This function parses the swc file into a pd.DataFrame. Each row is a vertex in the swc file with the following information: \n",
    "\n",
    "`sample number`\n",
    "\n",
    "`structure identifier`\n",
    "\n",
    "`x coordinate`\n",
    "\n",
    "`y coordinate`\n",
    "\n",
    "`z coordinate`\n",
    "\n",
    "`radius of dendrite`\n",
    "\n",
    "`sample number of parent`\n",
    "\n",
    "The coordinates are given in spatial units of micrometers ([swc specification](http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:00<00:00, 22.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>structure</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>r</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4713.0</td>\n",
       "      <td>4470.0</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>4721.0</td>\n",
       "      <td>4445.0</td>\n",
       "      <td>3849.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>4723.0</td>\n",
       "      <td>4446.0</td>\n",
       "      <td>3851.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4728.0</td>\n",
       "      <td>4449.0</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4746.0</td>\n",
       "      <td>4445.0</td>\n",
       "      <td>3858.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample  structure       x       y       z    r  parent\n",
       "0       1          0  4713.0  4470.0  3857.0  1.0      -1\n",
       "1       4        192  4721.0  4445.0  3849.0  1.0       1\n",
       "2       7         64  4723.0  4446.0  3851.0  1.0       4\n",
       "3       8          0  4728.0  4449.0  3852.0  1.0       7\n",
       "4      14          0  4746.0  4445.0  3858.0  1.0       8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_path = \"s3://mouse-light-viz/precomputed_volumes/brain1_segments\"\n",
    "seg_id = 2\n",
    "mip = 1\n",
    "df = read_s3(s3_path, seg_id, mip)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `swc_to_voxel`\n",
    "\n",
    "If we want to overlay the swc file with a corresponding image, we need to make sure that they are in the same coordinate space. Because an image in an array of voxels, it makes sense to convert the vertices in the dataframe from spatial units into voxel units.\n",
    "\n",
    "Given the `spacing` (spatial units/voxel) and `origin` (spatial units) of the image, `swc_to_voxel` does the conversion by using the following equation:\n",
    "\n",
    "$voxel = \\frac{spatial - origin}{spacing}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>structure</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>r</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-218839</td>\n",
       "      <td>-34826</td>\n",
       "      <td>-25748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>-218813</td>\n",
       "      <td>-34908</td>\n",
       "      <td>-25756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>-218806</td>\n",
       "      <td>-34905</td>\n",
       "      <td>-25754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-218789</td>\n",
       "      <td>-34895</td>\n",
       "      <td>-25753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-218729</td>\n",
       "      <td>-34908</td>\n",
       "      <td>-25747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample  structure       x      y      z    r  parent\n",
       "0       1          0 -218839 -34826 -25748  1.0      -1\n",
       "1       4        192 -218813 -34908 -25756  1.0       1\n",
       "2       7         64 -218806 -34905 -25754  1.0       4\n",
       "3       8          0 -218789 -34895 -25753  1.0       7\n",
       "4      14          0 -218729 -34908 -25747  1.0       8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacing = np.array([0.29875923,0.3044159,0.98840415])\n",
    "origin = np.array([70093.276,15071.596,29306.737])\n",
    "\n",
    "df_voxel = swc_to_voxel(df=df, spacing=spacing, origin=origin)\n",
    "df_voxel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `df_to_graph`\n",
    "A neuron is a graph with no cycles (tree). While napari does not support displaying graph objects, it can display multiple paths. \n",
    "\n",
    "The DataFrame already contains all the possible edges in the neurons. Each row in the DataFrame is an edge. For example, from the above we can see that `sample 2` has `parent 1`, which represents edge `(1,2)`. `sample 1` having `parent -1` means that `sample 1` is the root of the tree.\n",
    "\n",
    "`swc.df_to_graph` reads DataFrame and converts it into a networkx directional graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1650\n",
      "Number of edges: 1649\n",
      "\n",
      "\n",
      "Sample 1 coordinates (x,y,z)\n",
      "4713 4470 3857\n"
     ]
    }
   ],
   "source": [
    "G = df_to_graph(df)\n",
    "print('Number of nodes:', len(G.nodes))\n",
    "print('Number of edges:', len(G.edges))\n",
    "print('\\n')\n",
    "print('Sample 1 coordinates (x,y,z)')\n",
    "print(G.nodes[1]['x'],G.nodes[1]['y'],G.nodes[1]['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adj',\n",
       " '_node',\n",
       " '_pred',\n",
       " '_succ',\n",
       " 'add_edge',\n",
       " 'add_edges_from',\n",
       " 'add_node',\n",
       " 'add_nodes_from',\n",
       " 'add_weighted_edges_from',\n",
       " 'adj',\n",
       " 'adjacency',\n",
       " 'adjlist_inner_dict_factory',\n",
       " 'adjlist_outer_dict_factory',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'degree',\n",
       " 'edge_attr_dict_factory',\n",
       " 'edge_subgraph',\n",
       " 'edges',\n",
       " 'get_edge_data',\n",
       " 'graph',\n",
       " 'graph_attr_dict_factory',\n",
       " 'has_edge',\n",
       " 'has_node',\n",
       " 'has_predecessor',\n",
       " 'has_successor',\n",
       " 'in_degree',\n",
       " 'in_edges',\n",
       " 'is_directed',\n",
       " 'is_multigraph',\n",
       " 'name',\n",
       " 'nbunch_iter',\n",
       " 'neighbors',\n",
       " 'node_attr_dict_factory',\n",
       " 'node_dict_factory',\n",
       " 'nodes',\n",
       " 'number_of_edges',\n",
       " 'number_of_nodes',\n",
       " 'order',\n",
       " 'out_degree',\n",
       " 'out_edges',\n",
       " 'pred',\n",
       " 'predecessors',\n",
       " 'remove_edge',\n",
       " 'remove_edges_from',\n",
       " 'remove_node',\n",
       " 'remove_nodes_from',\n",
       " 'reverse',\n",
       " 'size',\n",
       " 'subgraph',\n",
       " 'succ',\n",
       " 'successors',\n",
       " 'to_directed',\n",
       " 'to_directed_class',\n",
       " 'to_undirected',\n",
       " 'to_undirected_class',\n",
       " 'update']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Points():\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        \n",
    "    def get_x(self):\n",
    "        return self.x\n",
    "    \n",
    "    def get_y(self):\n",
    "        return self.y\n",
    "    \n",
    "    def get_z(self):\n",
    "        return self.z\n",
    "    \n",
    "\n",
    "def get_voxel_info(df_voxel, sample_num):\n",
    "    for _, row in df_voxel.iterrows():\n",
    "        if int(row['sample']) == sample_num:\n",
    "            return Points(row['x'],  row['y'], row['z'])\n",
    "    \n",
    "    return None  # never reached\n",
    "\n",
    "\n",
    "def get_k_successors(seg_id, vertex_id, depth):\n",
    "    s3_path = \"s3://mouse-light-viz/precomputed_volumes/brain1_segments\"\n",
    "    mip = 1\n",
    "    \n",
    "    spacing = np.array([0.29875923,0.3044159,0.98840415])\n",
    "    origin = np.array([70093.276,15071.596,29306.737])\n",
    "    \n",
    "    df = read_s3(s3_path, seg_id, mip)\n",
    "    df_voxel = swc_to_voxel(df=df, spacing=spacing, origin=origin)\n",
    "\n",
    "    G = df_to_graph(df_voxel)\n",
    "    \n",
    "    from collections import deque\n",
    "    \n",
    "    unvisited_nodes = deque([vertex_id])\n",
    "    visited_nodes = []\n",
    "    visited_points = []\n",
    "    \n",
    "    while unvisited_nodes and depth > 0:\n",
    "        depth -= 1\n",
    "        \n",
    "        current_node = unvisited_nodes.popleft()\n",
    "        \n",
    "        if current_node in visited_nodes:\n",
    "            continue\n",
    "            \n",
    "        visited_nodes.append(current_node)\n",
    "        visited_points.append(get_voxel_info(df_voxel, current_node))\n",
    "        \n",
    "        \n",
    "        for child_node in G.successors(current_node):\n",
    "            unvisited_nodes.append(child_node)\n",
    "            \n",
    "    return visited_nodes, visited_points\n",
    "            \n",
    "\n",
    "nodes, points = get_k_successors(2,7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes)\n",
    "print(visted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `graph_to_paths`\n",
    "This function takes in a graph and returns a list of non-overlapping paths. The union of the paths forms the graph.\n",
    "\n",
    "The algorithm works by:\n",
    "\n",
    "1. Find longest path in the graph ([networkx.algorithms.dag.dag_longest_path](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.dag.dag_longest_path.html))\n",
    "2. Remove longest path from graph\n",
    "3. Repeat steps 1 and 2 until there are no more edges left in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = graph_to_paths(G=G)\n",
    "print(f\"The graph was decomposed into {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `ViewerModel.add_shapes`\n",
    "napari displays \"layers\". The most common layer is the image layer. In order to display the neuron, we use `path` from the [shapes](https://napari.org/tutorials/shapes) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_shapes(data=paths, shape_type='path', edge_color='white', name='Skeleton 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
